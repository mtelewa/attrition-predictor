{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **FeatureEngineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Further data preparation for the ML algorithm by performing feature engineering and splitting the dataset\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Dataset in outputs/datasets/cleaned/DatasetCleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Test dataset in outputs/datasets/cleaned/TestSetCleaned.csv\n",
        "* Train dataset in outputs/datasets/cleaned/TrainSetCleaned.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/attrition-predictor'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data does not have missing values, therefore we will not need any imputer. In the last notebook, we already dropped 7 columns from the dataset of 35 columns, leaving 28 columns including the target. The target `Attrition` was transformed from a categorical variable (Yes, No) to a numerical one (1, 0). The operation was done manually and mimics an ordinal encoder.\n",
        "\n",
        "As mentioned before, there are 8 categorical variables (after dropping `Over18`) including `Attrition`. These will be subjected to OrdinalCategoricalEncoder.\n",
        "\n",
        "As for the numerical data, we will have to look on their distribution (QQ plots and histogram)..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>...</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>Technical Degree</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>Sales</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Sales</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Attrition     BusinessTravel              Department  \\\n",
              "0   58          0      Travel_Rarely                   Sales   \n",
              "1   45          0      Travel_Rarely  Research & Development   \n",
              "2   40          0      Travel_Rarely                   Sales   \n",
              "3   36          0         Non-Travel                   Sales   \n",
              "4   25          1  Travel_Frequently                   Sales   \n",
              "\n",
              "   DistanceFromHome  Education    EducationField  EnvironmentSatisfaction  \\\n",
              "0                21          3     Life Sciences                        4   \n",
              "1                28          3  Technical Degree                        4   \n",
              "2                26          3         Marketing                        3   \n",
              "3                 8          4     Life Sciences                        1   \n",
              "4                24          1     Life Sciences                        3   \n",
              "\n",
              "   Gender  JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
              "0  Female               3  ...                  3                        3   \n",
              "1    Male               3  ...                  4                        4   \n",
              "2    Male               3  ...                  3                        2   \n",
              "3    Male               2  ...                  3                        2   \n",
              "4    Male               1  ...                  3                        4   \n",
              "\n",
              "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
              "0                 1                29                      2                2   \n",
              "1                 1                 8                      3                3   \n",
              "2                 1                 8                      3                2   \n",
              "3                 0                10                      1                3   \n",
              "4                 0                 1                      4                3   \n",
              "\n",
              "  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
              "0              1                   0                        0   \n",
              "1              5                   4                        0   \n",
              "2              7                   7                        7   \n",
              "3             10                   7                        0   \n",
              "4              1                   0                        1   \n",
              "\n",
              "   YearsWithCurrManager  \n",
              "0                     0  \n",
              "1                     3  \n",
              "2                     5  \n",
              "3                     9  \n",
              "4                     0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TrainSet = pd.read_csv(f\"outputs/datasets/cleaned/TrainSetCleaned.csv\")\n",
        "TrainSet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will perform:\n",
        "* Visualize data distribution to decide which numerical data to apply transformation to\n",
        "* Numerical data transformation\n",
        "* Categorical encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numerical data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot all numerical columns and calculate their skewness and kurtosis to see how far they are from normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pingouin as pg\n",
        "\n",
        "def plot_distribution(dataframe):\n",
        "\n",
        "    for col in dataframe.columns:\n",
        "        if dataframe[col].dtype=='int64':\n",
        "            print(f\"*** {col} ***\")\n",
        "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,4), width_ratios = [1, 1])\n",
        "            sns.histplot(data=dataframe, x=col, ax=axes[0], kde=True, multiple=\"stack\")\n",
        "            qqplot = pg.qqplot(dataframe[col], dist='norm', ax=axes[1])\n",
        "            qqplot.set(xlabel=None)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            print(f\"skewness: {dataframe[col].skew().round(2)} | kurtosis: {dataframe[col].kurtosis().round(2)}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "plot_distribution(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice there are 11 numerical features which are discrete (no. of unique values <= 7), we will drop these from the analysis to focus on the continuous numerical variables. We will also drop `Age` from the analysis because it was apparent from last notebook, that age distribution was very close to normal distribution.\n",
        "\n",
        "Note: a value of 7 to distinguish discrete from continuous was chosen arbitrarly from looking at figures output from the above cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apply_transform_to = []\n",
        "for col in TrainSet.drop(labels='Age', axis=1).columns:\n",
        "    if len(TrainSet[col].unique()) > 7 and TrainSet[col].dtype=='int64':\n",
        "        apply_transform_to.append(col)\n",
        "\n",
        "df_continuous = TrainSet.filter(apply_transform_to)\n",
        "plot_distribution(df_continuous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numerical data transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the following function to compare the data distribution before and after the transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_skew_kurtosis(df,col, moment):\n",
        "    \"\"\"\n",
        "    This function is adapted from the feature engineering lesson\n",
        "    \"\"\"\n",
        "    print(f\"{moment}  | skewness: {df[col].skew().round(2)} | kurtosis: {df[col].kurtosis().round(2)}\")\n",
        "\n",
        "def compare_distributions_before_and_after_applying_transformer(df, df_transformed1, df_transformed2, method1, method2, items=None):\n",
        "    if items != None:\n",
        "        df = df.filter(items)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    for col in df.columns:\n",
        "        print(f\"*** {col} ***\")\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(8,8))\n",
        "\n",
        "        plot1 = sns.histplot(data=df, x=col, kde=True, ax=axes[0,0])\n",
        "        plot2 = sns.histplot(data=df_transformed1, x=col, kde=True, ax=axes[1,0], color=['green'])\n",
        "        plot3 = sns.histplot(data=df_transformed2, x=col, kde=True, ax=axes[2,0], color=['red'])\n",
        "        plot1.set(xlabel=None)\n",
        "        plot2.set(xlabel=None)\n",
        "        plot1.set_title('Before Transform')\n",
        "        plot2.set_title(method1)\n",
        "        plot3.set_title(method2)\n",
        "        \n",
        "        qqplot1 = pg.qqplot(df[col], dist='norm',ax=axes[0,1])\n",
        "        qqplot2 = pg.qqplot(df_transformed1[col], dist='norm',ax=axes[1,1])\n",
        "        qqplot1.set(xlabel=None)\n",
        "        qqplot2.set(xlabel=None)        \n",
        "        pg.qqplot(df_transformed2[col], dist='norm',ax=axes[2,1])\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        calculate_skew_kurtosis(df, col, moment='before transformation')\n",
        "        calculate_skew_kurtosis(df_transformed1, col, moment=f'after {method1}')\n",
        "        calculate_skew_kurtosis(df_transformed2, col, moment=f'after {method2}')\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can not apply logarithmic, reciprocal and BoxCox transformers since we have zeros in our data. Two exceptions from this are the columns `PercentSalaryHike` and `DistanceFromHome`, which will be treated separately after the following analysis, if it was not successful in getting a normal distribution. Therefore, we proceed with the power transformer and the Yeo Johnson transformer to all numerical variables. \n",
        "\n",
        "We set the pipeline with the transformer and then fit and transform the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine import transformation as vt\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline_power = Pipeline([\n",
        "      ( 'pt', vt.PowerTransformer() )\n",
        "  ])\n",
        "pipeline_YeoJohnson = Pipeline([\n",
        "      ('yj', vt.YeoJohnsonTransformer() )\n",
        "  ])\n",
        "\n",
        "df_transformed_power = pipeline_power.fit_transform(df_continuous)\n",
        "df_transformed_YeoJohnson = pipeline_YeoJohnson.fit_transform(df_continuous)\n",
        "\n",
        "compare_distributions_before_and_after_applying_transformer(df_continuous, df_transformed_power, df_transformed_YeoJohnson, 'Power Transform', 'YeoJohnson Transform')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comments on the numerical transformation:\n",
        "* In all the plots, YeoJohnson transformation performance with superior to the Power transformation when it comes to skewness. That means the data becomes more symmetric at the center point.\n",
        "* As for kurtosis, except for `YearsAtCompany`, YeoJohnson transformation generated data with higher negative kurtosis. Meaning that the distribution has thinner tails than the original data as well as the Power transformed data\n",
        "\n",
        "Generally, the transformed data distribution resembles a normal distribution more than the original data **only for 3 variables**. These are `MonthlyIncome`, `TotalWorkingYears`, `YearsAtCompany`.\n",
        "\n",
        "Therefore, we proceed with YeoJohnson transformation only on these variables in the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we conclude, we run a numerical transformation on `PercentSalaryHike` and `DistanceFromHome` with other transformers. As they have non-zero values, we can perform reciprocal and logarithmic transformations to see if the distribution will get close to a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_log = Pipeline([\n",
        "      ( 'log', vt.LogTransformer(variables=['PercentSalaryHike','DistanceFromHome']) )\n",
        "  ])\n",
        "pipeline_reciprocal = Pipeline([\n",
        "      ( 'reciprocal', vt.ReciprocalTransformer(variables=['PercentSalaryHike','DistanceFromHome']) )\n",
        "  ])\n",
        "\n",
        "df_transformed_log = pipeline_log.fit_transform(df_continuous)\n",
        "df_transformed_reciprocal = pipeline_reciprocal.fit_transform(df_continuous)\n",
        "\n",
        "compare_distributions_before_and_after_applying_transformer(df_continuous,\n",
        "                                                            df_transformed_log,\n",
        "                                                            df_transformed_reciprocal,\n",
        "                                                            'Log Transform', 'Reciprocal Transform',\n",
        "                                                            items=['PercentSalaryHike','DistanceFromHome'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the distribution does not improve. Finally, we perform the chosen numerical transformation on the chosen variables in the TrainSet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_YeoJohnson = Pipeline([\n",
        "      ('yj', vt.YeoJohnsonTransformer(variables=['MonthlyIncome', 'TotalWorkingYears', 'YearsAtCompany']) )\n",
        "  ])\n",
        "\n",
        "TrainSet_transformed_YeoJohnson = pipeline_YeoJohnson.fit_transform(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Ordinal Categorical Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We perform categorical encoding to transform categorical variables into integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables to apply the transformation to are: ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\n",
            "\n",
            "\n",
            "-------------------Before Transformation--------------------------\n",
            "\n",
            "\n",
            "BusinessTravel \n",
            "['Travel_Rarely' 'Non-Travel' 'Travel_Frequently'] \n",
            "\n",
            "\n",
            "Department \n",
            "['Sales' 'Research & Development' 'Human Resources'] \n",
            "\n",
            "\n",
            "EducationField \n",
            "['Life Sciences' 'Technical Degree' 'Marketing' 'Medical'\n",
            " 'Human Resources' 'Other'] \n",
            "\n",
            "\n",
            "Gender \n",
            "['Female' 'Male'] \n",
            "\n",
            "\n",
            "JobRole \n",
            "['Manager' 'Research Scientist' 'Sales Executive' 'Sales Representative'\n",
            " 'Laboratory Technician' 'Manufacturing Director' 'Human Resources'\n",
            " 'Research Director' 'Healthcare Representative'] \n",
            "\n",
            "\n",
            "MaritalStatus \n",
            "['Married' 'Single' 'Divorced'] \n",
            "\n",
            "\n",
            "OverTime \n",
            "['Yes' 'No'] \n",
            "\n",
            "\n",
            "-------------------After Transformation--------------------------\n",
            "\n",
            "\n",
            "BusinessTravel \n",
            "[0 1 2] \n",
            "\n",
            "\n",
            "Department \n",
            "[0 1 2] \n",
            "\n",
            "\n",
            "EducationField \n",
            "[0 1 2 3 4 5] \n",
            "\n",
            "\n",
            "Gender \n",
            "[0 1] \n",
            "\n",
            "\n",
            "JobRole \n",
            "[0 1 2 3 4 5 6 7 8] \n",
            "\n",
            "\n",
            "MaritalStatus \n",
            "[0 1 2] \n",
            "\n",
            "\n",
            "OverTime \n",
            "[0 1] \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "apply_transform_to = []\n",
        "\n",
        "for col in TrainSet.columns:\n",
        "      if TrainSet[col].dtype=='object':\n",
        "            apply_transform_to.append(col)\n",
        "\n",
        "print(f'Variables to apply the transformation to are: {apply_transform_to}')\n",
        "print('\\n')\n",
        "print(f'-------------------Before Transformation--------------------------')\n",
        "print('\\n')\n",
        "# Before transformation\n",
        "for col in TrainSet.filter(apply_transform_to).columns.to_list():\n",
        "      print(f\"{col} \\n{TrainSet[col].unique()} \\n\\n\")\n",
        "\n",
        "# Transforma and fit\n",
        "pipeline = Pipeline([\n",
        "      ('ordinal_encoder', OrdinalEncoder(encoding_method='arbitrary') )\n",
        "])\n",
        "\n",
        "TrainSet_transformed_ordinal = pipeline.fit_transform(TrainSet.filter(apply_transform_to))\n",
        "\n",
        "print(f'-------------------After Transformation--------------------------')\n",
        "print('\\n')\n",
        "# Check that transformation happened\n",
        "for col in TrainSet_transformed_ordinal.filter(apply_transform_to).columns.to_list():\n",
        "      print(f\"{col} \\n{TrainSet_transformed_ordinal[col].unique()} \\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Smart correlated selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We look for groups of features that correlate amongst themselves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
        "\n",
        "corr_sel.fit_transform(df_engineering)\n",
        "corr_sel.correlated_feature_sets_"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
